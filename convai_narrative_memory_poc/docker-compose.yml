services:
  kafka:
    image: confluentinc/cp-kafka:latest
    depends_on: []
    environment:
      CLUSTER_ID: "A8758710-53A4-423A-A3F9-87F494D38925"
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
      KAFKA_LISTENERS: "PLAINTEXT://:9092,CONTROLLER://:9093"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka:9092"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    ports: ["9092:9092"]

  qdrant:
    image: qdrant/qdrant:v1.10.1
    ports: ["6333:6333"]
    volumes: ["qdrant_storage:/qdrant/storage"]

  ollama:
    image: ollama/ollama:latest
    ports: ["11434:11434"]
    volumes: ["ollama_storage:/root/.ollama"]
    environment:
      - OLLAMA_HOST=0.0.0.0:11434

  indexer:
    build:
      context: ../
      dockerfile: ./convai_narrative_memory_poc/workers/indexer/Dockerfile
    environment:
      - PYTHONUNBUFFERED=1
      - KAFKA_BOOTSTRAP=kafka:9092
      - QDRANT_URL=http://qdrant:6333
      - QDRANT_COLLECTION=anchors
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-ollama:bge-m3}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://ollama:11434}
    depends_on: [kafka, qdrant, ollama]

  resonance:
    build:
      context: ../
      dockerfile: ./convai_narrative_memory_poc/workers/resonance/Dockerfile
    environment:
      - PYTHONUNBUFFERED=1
      - KAFKA_BOOTSTRAP=kafka:9092
      - QDRANT_URL=http://qdrant:6333
      - QDRANT_COLLECTION=anchors
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-ollama:bge-m3}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://ollama:11434}
    depends_on: [kafka, qdrant, ollama]

  reteller:
    build:
      context: ../
      dockerfile: ./convai_narrative_memory_poc/workers/reteller/Dockerfile
    environment:
      - PYTHONUNBUFFERED=1
      - KAFKA_BOOTSTRAP=kafka:9092
      - OPENAI_API_KEY
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}
      - PORTKEY_API_KEY=${PORTKEY_API_KEY}
      - PORTKEY_BASE_URL=${PORTKEY_BASE_URL:-https://api.portkey.ai/v1}
      - PORTKEY_CONFIG_ID=${PORTKEY_CONFIG_ID}
      - PORTKEY_MODEL=${PORTKEY_MODEL:-mistral-large}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://ollama:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3}
    depends_on: [kafka, ollama]

  tools:
    build:
      context: ../
      dockerfile: ./convai_narrative_memory_poc/tools/Dockerfile
    environment:
      - KAFKA_BOOTSTRAP=kafka:9092
      - QDRANT_URL=http://qdrant:6333
      - QDRANT_COLLECTION=anchors
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-ollama:bge-m3}
      - PORTKEY_API_KEY=${PORTKEY_API_KEY}
      - PORTKEY_BASE_URL=${PORTKEY_BASE_URL:-https://api.portkey.ai/v1}
      - PORTKEY_CONFIG_ID=${PORTKEY_CONFIG_ID}
      - PORTKEY_EMBEDDING_MODEL=${PORTKEY_EMBEDDING_MODEL:-cohere-embed-v3}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://ollama:11434}
    depends_on: [kafka, qdrant, ollama]
    volumes:
      - ../results:/app/results

  chatbot:
    build:
      context: ../
      dockerfile: ./convai_narrative_memory_poc/tools/Dockerfile
    environment:
      - KAFKA_BOOTSTRAP=kafka:9092
      - PYTHONUNBUFFERED=1
    depends_on: [kafka, qdrant, ollama, indexer, resonance, reteller]
    stdin_open: true
    tty: true
    command: python convai_narrative_memory_poc/tools/chatbot.py

  streamlit:
    build:
      context: ../
      dockerfile: ./convai_narrative_memory_poc/tools/Dockerfile
    environment:
      - KAFKA_BOOTSTRAP=kafka:9092
      - PYTHONUNBUFFERED=1
      - PORTKEY_API_KEY=${PORTKEY_API_KEY}
      - PORTKEY_BASE_URL=${PORTKEY_BASE_URL:-https://api.portkey.ai/v1}
      - PORTKEY_MODEL=${PORTKEY_MODEL:-mistral-large}
      - PORTKEY_CONFIG_ID=${PORTKEY_CONFIG_ID}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://ollama:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3}
    depends_on: [kafka, qdrant, ollama, indexer, resonance, reteller]
    ports:
      - "8501:8501"
    command: streamlit run convai_narrative_memory_poc/ui/streamlit_app.py --server.address=0.0.0.0

volumes:
  qdrant_storage:
  ollama_storage:
